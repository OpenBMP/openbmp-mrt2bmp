import urllib2
import os
import datetime
import shutil
import json
from threading import Thread, Lock
from multiprocessing import Manager, Process

NAME_OF_DOWNLOAD_TRACK_FILE = "download_track.json"
ROUTER_FILE_MUTEX = dict()

class Downloader_Thread(Thread):

    def __init__(self, download_queue, master_dir, router_name):

        Thread.__init__(self)

        self.route_view_dir_path = master_dir
        self.download_queue = download_queue
        self.router_name = router_name

    def run(self):

        try:

            while True:
                df = self.download_queue.get()
                #print df

                path_parts = df[0].split("/")

                path = os.path.join(self.route_view_dir_path, df[1], path_parts[-3], path_parts[-2], path_parts[-1])
                key = os.path.join(path_parts[-3], path_parts[-2], path_parts[-1])

                if os.path.isfile(path):
                    os.remove(path)

                # Create temporary path to download the mrt file.
                temp_file_name = 'download-mrt'
                temp_path = os.path.join(self.route_view_dir_path, df[1], path_parts[-3], path_parts[-2], temp_file_name)

                # Check if there is existing .download file, then delete it.
                if os.path.isfile(temp_path):
                    os.remove(temp_path)

                # Get file size and last modification date.
                req = urllib2.Request(df[0])

                url_handle = urllib2.urlopen(req)

                headers = url_handle.info()

                etag = headers.getheader("ETag")[1:-1]
                last_modified = headers.getheader("Last-Modified")
                #print headers

                if not self.__checkFileMetadataInDownloadTrack(df[1], key, etag, last_modified):

                    # Download the file.
                    with open(temp_path,'wb') as output:
                        output.write(url_handle.read())

                    # Rename the downloaded file
                    os.rename(temp_path, path)

                    # Save downloaded file info in track file.
                    self.__addFileMetadataToDownloadTrack(df[1], key, etag, last_modified)

                self.download_queue.task_done()

        except urllib2.URLError as e:
            print e.reason

        except (EOFError,IOError) as e:
            pass

    def __addFileMetadataToDownloadTrack(self, router_name, file_url, etag, file_modification_date):

        global ROUTER_FILE_MUTEX

        ROUTER_FILE_MUTEX[router_name].acquire()

        try:
            file_path = os.path.join(self.route_view_dir_path, router_name, NAME_OF_DOWNLOAD_TRACK_FILE)

            # Read the corresponding json file.
            with open(file_path) as f:
                data = json.load(f)

            data[file_url] = {"e-tag": etag, "file_modification_date": file_modification_date}

            # Write the data object to the corresponding json file.
            with open(file_path, 'w') as f:
                json.dump(data, f, sort_keys=True, indent=4)

        except:
            pass

        finally:
            ROUTER_FILE_MUTEX[router_name].release()

    def __checkFileMetadataInDownloadTrack(self, router_name, file_url, etag, file_modification_date):

        global ROUTER_FILE_MUTEX

        ROUTER_FILE_MUTEX[router_name].acquire()

        try:
            file_path = os.path.join(self.route_view_dir_path, router_name, NAME_OF_DOWNLOAD_TRACK_FILE)

            # Add file metadata to the corresponding file.
            with open(file_path) as f:
                data = json.load(f)

            if not data.get(file_url) is None:
                if data[file_url]['e-tag'] == etag and data[file_url]['file_modification_date'] == file_modification_date:
                    return True

                else:
                    return False

            else:
                return False

        except:
            pass

        finally:
            ROUTER_FILE_MUTEX[router_name].release()
            return False


class RouteDataSynchronizer(Process):

    def __init__(self, cfg, log_queue):
        Process.__init__(self)
        self._stopped = False
        self.cfg = cfg
        self.LOG = None
        self._log_queue = log_queue

        try:

            self.manager = Manager()

            self.web_address = cfg['router_data']['web_source_address']
            self.route_view_dir_path = cfg['router_data']['save_directory_path']

            self.downloader_threads = dict()
            self.download_queues = dict()

            self.__createDirIfNotExist(self.route_view_dir_path)

        except IOError as e:
            print e

    def run(self):

        try:
            """ Override """
            routers = self.__getListOfRouters()
            # Create inprogress file if does not exist.
            for r in routers:
                self.__createDownloadTrackFile(r[0])

                inprogress_file_path = os.path.join(self.route_view_dir_path, r[0], "inprogress")
                if not os.path.isfile(inprogress_file_path):
                    # Create the file.
                    file = open(inprogress_file_path, "w")
                    file.write("")
                    file.close()

            # Create a queue for each router.
            for r in routers:
                self.download_queues[r[0]] = self.manager.Queue(self.cfg['router_data']['max_download_queue_size'])

            self.__createDownloaderThreadPool(routers)

            for r in routers:
                #print r
                if not self.stopped():

                    url = self.web_address + r[1] + '/'
                    router_name = r[0]

                    response = urllib2.urlopen(url)
                    html = response.read()

                    if html.find('alt="[DIR]"') != -1:
                        # Directory listing html.
                        file_list_html = html.split('alt="[DIR]"></td><td><a href="')
                        del file_list_html[0]

                        for n, l in enumerate(file_list_html):
                            file_list_html[n] = l[:l.find('">')]

                        file_list_html.sort(reverse=True)

                        for link in file_list_html:

                            if link != 'SH_IP_BGP/' and not self.stopped():
                                url_link = url + link
                                result = self.__findLatestMrtFiles(url_link, router_name)

                                if result is not None:
                                    break

                else:
                    break

            for r in routers:
                self.download_queues[r[0]].join()

                # Delete existing inprogress file in each router.
                inprogress_file_path = os.path.join(self.route_view_dir_path, r[0], "inprogress")
                if os.path.isfile(inprogress_file_path):
                    # Delete the file.
                    os.remove(inprogress_file_path)

        except KeyboardInterrupt:
            print "Stopped by user"
            self.stop()

        except (urllib2.URLError, EOFError, IOError) as e:
            pass

    def __findLatestMrtFiles(self, url, router_name):

        date = None

        try:

            response = urllib2.urlopen(url)
            html = response.read()

            if html.find('alt="[DIR]"') != -1:
                # Directory listing html.
                file_list_html = html.split('alt="[DIR]"></td><td><a href="')
                del file_list_html[0]

                l = file_list_html[0]
                link = l[:l.find('">')]
                url_link = url + link

                if link == "RIBS/":
                    date = self.__findLatestRibFile(url_link, router_name)

                l = file_list_html[1]
                link = l[:l.find('">')]
                url_link = url + link

                if link == "UPDATES/" and date is not None:
                    self.__findLatestUpdateFiles(url_link, router_name, date)

                return date

        except urllib2.URLError as e:
            print e.reason

        except KeyboardInterrupt:
            self.stop()

    def __findLatestRibFile(self, url, router_name):

        try:

            response = urllib2.urlopen(url)
            html = response.read()

            date = None

            if html.find('alt="[   ]"') != -1:
                # Last depth directory, it has list of mrt files.
                file_list_html = html.split('alt="[   ]"></td><td><a href="')
                del file_list_html[0]

                l = file_list_html[-1]

                link = l[:l.find('">')]

                # Check if file exists in the router's download track file.
                url_link = url + link
                url_parts = url_link.split("/")

                # Search the link in the download track file.
                # If it does not exist, then delete whole router directory and create again.
                global ROUTER_FILE_MUTEX

                ROUTER_FILE_MUTEX[router_name].acquire()

                try:
                    file_path = os.path.join(self.route_view_dir_path, router_name, NAME_OF_DOWNLOAD_TRACK_FILE)

                    # Add file metadata to the corresponding file.
                    with open(file_path) as f:
                        data = json.load(f)

                    path_parts = url_link.split("/")

                    key = os.path.join(path_parts[-3], path_parts[-2], path_parts[-1])

                    if data.get(key) is None:
                        self.__createDirIfNotExist(
                            os.path.join(self.route_view_dir_path, router_name, url_parts[-3], url_parts[-2]))

                        self.download_queues[router_name].put((url_link, router_name))

                finally:
                    ROUTER_FILE_MUTEX[router_name].release()

                # Parse date of the file.
                tokens = link.split('.')
                date = tokens[1] + tokens[2]
                date = datetime.datetime(int(date[0:4]), int(date[4:6]), int(date[6:8]), int(date[8:10]), int(date[10:]))

                return date

        except (urllib2.URLError,IOError):
            pass

        except KeyboardInterrupt:
            self.stop()

    def __findLatestUpdateFiles(self, url, router_name, rib_date):

        try:

            response = urllib2.urlopen(url)
            html = response.read()

            if html.find('alt="[   ]"') != -1:
                # Last depth directory, it has list of mrt files.
                file_list_html = html.split('alt="[   ]"></td><td><a href="')
                del file_list_html[0]

                for l in file_list_html:

                    link = l[:l.find('">')]

                    # Check if file exists in the router's download track file.
                    url_link = url + link
                    url_parts = url_link.split("/")

                    # Parse date of the file.
                    tokens = link.split('.')
                    date = tokens[1] + tokens[2]
                    date = datetime.datetime(int(date[0:4]), int(date[4:6]), int(date[6:8]), int(date[8:10]),
                                             int(date[10:]))

                    if date >= rib_date:

                        self.__createDirIfNotExist(os.path.join(self.route_view_dir_path, router_name, url_parts[-3], url_parts[-2]))

                        self.download_queues[router_name].put((url_link, router_name))

        except urllib2.URLError as e:
            print e.reason

        except KeyboardInterrupt:
            pass

    def __createDirIfNotExist(self, path):
        if not os.path.exists(path):
            os.makedirs(path)

    def __createDownloaderThreadPool(self, routers):
        for r in routers:
            t = Downloader_Thread(self.download_queues[r[0]], self.route_view_dir_path, r[0])
            t.setDaemon(True)
            t.start()

            self.downloader_threads[r[0]] = t

    def __getListOfRouters(self):
        response = urllib2.urlopen(self.web_address)
        html = response.read()

        list_start = html.find("<LI>")
        list_end = html.find("</LI>")

        # Get routers html block.
        all_routers_html = html[list_start+4:list_end-6]

        # Get list of router htmls.
        list_of_routers_html = all_routers_html.split("<br>")

        # Delete last element because last link is not a router.
        del list_of_routers_html[len(list_of_routers_html)-1]

        router_list = []

        for r in list_of_routers_html:
            router_link = r[r.find('HREF="') + 6:r.find('">')]

            start_index_name = r.rfind('quagga bgpd') + 18

            end_index_1 = r.find(')', start_index_name)
            end_index_2 = r.find(' ', start_index_name)

            router_name = r[start_index_name:min(end_index_1,end_index_2)].strip()

            # Initiliaze file lock for each router and adds it to dictionary of locks.
            global ROUTER_FILE_MUTEX
            ROUTER_FILE_MUTEX[router_name] = Lock()
            #print router_name

            router_list.append((router_name, router_link))

        return router_list

    def __createDownloadTrackFile(self, router_name):

        if not os.path.isdir(os.path.join(self.route_view_dir_path, router_name)):
            os.makedirs(os.path.join(self.route_view_dir_path, router_name))

        if not os.path.isfile(os.path.join(self.route_view_dir_path, router_name, NAME_OF_DOWNLOAD_TRACK_FILE)):
            empty_dict = dict()

            with open(os.path.join(self.route_view_dir_path, router_name, NAME_OF_DOWNLOAD_TRACK_FILE), 'w') as outfile:
                json.dump(empty_dict, outfile, sort_keys=True, indent=4)

    def clean_temp_files(self):
        routers = self.__getListOfRouters()

        for r in routers:
            # Delete existing inprogress file in each router.
            inprogress_file_path = os.path.join(self.route_view_dir_path, r[0], "inprogress")

            # Delete the file.
            try:
                os.remove(inprogress_file_path)
            except OSError:
                pass

    def stop(self):
        self._stopped = True

    def stopped(self):
        return self._stopped